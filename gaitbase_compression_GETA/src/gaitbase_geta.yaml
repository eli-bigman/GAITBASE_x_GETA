data_cfg:
  dataset_name: CASIA-B
  dataset_root: /kaggle/working/CASIA-B-pkl
  dataset_partition: ./datasets/CASIA-B/CASIA-B.json
  num_workers: 4
  remove_no_gallery: false # Remove probe if no gallery for it
  test_dataset_name: CASIA-B

evaluator_cfg:
  enable_float16: true
  restore_ckpt_strict: true
  restore_hint: 0 # Resume from iteration 16000
  save_name: GaitBase_GETA_60K_Production  # ðŸŽ¯ Match trainer save_name
  sampler:
    batch_shuffle: false
    batch_size: 8  # Optimized for memory and performance
    sample_type: all_ordered # all indicates whole sequence used to test, while ordered means input sequence by its natural order; Other options:   fixed_unordered
    frames_all_limit: 360 # Balanced performance/memory for production
  metric: euc # cos
  transform:
    - type: BaseSilCuttingTransform

loss_cfg:
  - loss_term_weight: 1.0
    margin: 0.2
    type: TripletLoss
    log_prefix: triplet
  - loss_term_weight: 1.0
    scale: 16
    type: CrossEntropyLoss
    log_prefix: softmax
    log_accuracy: true

model_cfg:
  model: Baseline
  backbone_cfg:
    type: ResNet9
    block: BasicBlock
    channels: # Layers configuration for automatically model construction
      - 64
      - 128
      - 256
      - 512
    layers:
      - 1
      - 1
      - 1
      - 1
    strides:
      - 1
      - 2
      - 2
      - 1
    maxpool: false
  SeparateFCs:
    in_channels: 512
    out_channels: 256
    parts_num: 16
  SeparateBNNecks:
    class_num: 74
    in_channels: 256
    parts_num: 16
  bin_num:
    - 16

optimizer_cfg:
  lr: 0.1
  momentum: 0.9
  solver: SGD
  weight_decay: 0.0005

scheduler_cfg:
  gamma: 0.1
  milestones: # Learning Rate Reduction at each milestones
    - 20000
    - 40000
    - 50000
  scheduler: MultiStepLR

# GETA-specific configurations
geta_cfg:
  target_group_sparsity: 0.7  # 70% compression
  start_pruning_ratio: 0.1    # Start pruning at 10% of training
  pruning_duration_ratio: 0.25 # Finish pruning at 25% of training
  pruning_periods: 10
  visualize_dependency: true


trainer_cfg:
  enable_float16: false # half_percesion float for memory reduction and speedup set to false to let GETA optimization work
  fix_BN: false
  with_test: false # Set to false to focus on training for production run
  log_iter: 500  # Log every 500 iterations for good monitoring
  restore_ckpt_strict: true
  restore_hint: 48000 # Resume from iteration 48000
  optimizer_reset: true     # Add this - skip loading optimizer state
  scheduler_reset: true    # Add this - skip loading scheduler state 
  save_iter: 2000  # Save every 2000 iterations (25 checkpoints total for 40K training)
  save_name: GaitBase_GETA_60K_Production  #  Production model name with iteration count
  sync_BN: true
  total_iter: 60000  # Full production training (optimal for high accuracy)
  sampler:
    batch_shuffle: true
    batch_size:
      - 4 # TripletSampler, batch_size[0] indicates Number of Identity (reduced from 8)
      - 8 #                 batch_size[1] indicates Samples sequqnce for each Identity (reduced from 16)
    frames_num_fixed: 30 # fixed frames number for training
    frames_num_max: 40 # max frames number for unfixed training
    frames_num_min: 20 # min frames number for unfixed traing
    sample_type: fixed_unordered # fixed control input frames number, unordered for controlling order of input tensor; Other options: unfixed_ordered or all_ordered
    type: TripletSampler
  transform:
    - type: Compose
      trf_cfg:
        - type: BaseSilCuttingTransform
        - type: RandomRotate
          prob: 0.3
        - type: RandomErasing
          prob: 0.3
